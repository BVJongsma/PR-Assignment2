{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required libraries\n",
    "\"\"\"\n",
    "!pip install imblearn\n",
    "!pip install pyQt5\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install seeaborn\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb052813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PyQt5\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "%matplotlib qt \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dataloader import *\n",
    "import preprocessing\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#Using GridSearch to find the optimal value of K number of nearest neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#metrics for analysing our model\n",
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# oversampling technique\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b531c",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1beac219",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = Dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84f809",
   "metadata": {},
   "source": [
    "#### Scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d2424",
   "metadata": {},
   "source": [
    "scale all variables to have a mean of 0 and standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c6a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing.scale(handler.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cee63",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb1c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples/records :  801\n",
      "Maximum value in the features data 20.7788287118\n",
      "Minimum value in the features data 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of samples/records : \",len(handler.data))\n",
    "print(\"Maximum value in the features data\",np.amax(handler.data))\n",
    "print(\"Minimum value in the features data\",np.amin(handler.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c44827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "470feddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes and number of instances for each class:\n",
      "{'BRCA': 300, 'COAD': 78, 'KIRC': 146, 'LUAD': 141, 'PRAD': 136}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(handler.labels, return_counts=True)\n",
    "print(\"Classes and number of instances for each class:\")\n",
    "print(dict(zip(unique, counts)))\n",
    "plt.bar(unique,counts)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Different types of tumour\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7adca",
   "metadata": {},
   "source": [
    "We notice that there is class imbalance and we can use *SMOTE(Synthetic Minority Oversampling Technique)* for increasing instances of the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a0340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 801\n",
      "Number of genes: 20531\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\",len(data))\n",
    "print(\"Number of genes:\",len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfad95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(handler.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e5c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2,init='random').fit_transform(handler.data)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(2, figsize=(12, 12))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_title(\"TSNE plot on original data\")\n",
    "ax.scatter(X_embedded.T[0], X_embedded.T[1], color=color[labels])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a62d31",
   "metadata": {},
   "source": [
    "#### Split original dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5978ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split  in test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(handler.data, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387aae00",
   "metadata": {},
   "source": [
    "## Feature selection and Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30bea191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 397)\n",
      "Number of genes after dimension reduction using PCA: 397\n",
      "Explained variance of new dataset using PCA: 0.9501489407078344\n",
      "\n",
      "(640, 531)\n",
      "Number of genes after dimension reduction using SVD: 531\n",
      "Explained variance of new dataset using SVD: 0.9826082141870891\n"
     ]
    }
   ],
   "source": [
    "#with pca extract eigen pairs that explains 95% of the variance in the data.\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "#SVD dimension reduction\n",
    "svd = TruncatedSVD(n_components=531, random_state=0)\n",
    "\n",
    "#simultanously calculate eigen pairs and transform our data into the new coordinate frame\n",
    "principalComponents = pca.fit_transform(X_train)    #X_train_pca    #y_train\n",
    "svd_reduced_data = svd.fit_transform(X_train)    #X_train_svd       #y_train\n",
    "\n",
    "#check the amount of dimensions left after pca\n",
    "print(principalComponents.shape)\n",
    "print(\"Number of genes after dimension reduction using PCA:\",principalComponents.shape[1])\n",
    "print(\"Explained variance of new dataset using PCA:\",pca.explained_variance_ratio_.sum())\n",
    "print(\"\")\n",
    "print(svd_reduced_data.shape)\n",
    "print(\"Number of genes after dimension reduction using SVD:\",svd_reduced_data.shape[1])\n",
    "print(\"Explained variance of new dataset using SVD:\",svd.explained_variance_ratio_.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "#plot 3 most important principle components (3D plot)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(3,figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_title(\"Visualise data after applying PCA\")\n",
    "ax.scatter(principalComponents.T[0], principalComponents.T[1], principalComponents.T[2], color=color[labels])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1af955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "#plot 3 most important principle components (3D plot)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(4,figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_title(\"Visualise data after applying SVD\")\n",
    "ax.scatter(svd_reduced_data.T[0], svd_reduced_data.T[1], svd_reduced_data.T[2], color=color[labels])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ea802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split  in test and train\n",
    "#X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_train, y_train, test_size=0.20)\n",
    "\n",
    "#split  in test and train\n",
    "#X_train_svd, X_test_svd, y_train_svd, y_test_svd = train_test_split(svd_reduced_data, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002215ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5, figsize=(12, 12))\n",
    "ax = sn.heatmap(handler.data)\n",
    "ax.set_title(\"Correlation heatmap of all dimensions on the original data\")\n",
    "\n",
    "#plt.figure(6, figsize=(12, 12))\n",
    "#ax = sn.heatmap(principalComponents)\n",
    "#ax.set_title(\"Correlation heatmap of all dimensions after PCA\")\n",
    "\n",
    "#plt.figure(7, figsize=(12, 12))\n",
    "#ax = sn.heatmap(svd_reduced_data)\n",
    "#ax.set_title(\"Correlation heatmap of all dimensions after SVD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e8f2f",
   "metadata": {},
   "source": [
    "## Augmentation (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b26826",
   "metadata": {},
   "source": [
    "- As noticed from the classs distribution, there is class imbalance since there are very few samples in the 'COAD' class.\n",
    "- We apply Synthetic Minority Oversampling Technique to oversample the classes such that each class has equal number of samples\n",
    "- SMOTE is applied after feature extraction/reduction is done\n",
    "- refer (https://arxiv.org/ftp/arxiv/papers/1403/1403.1949.pdf#:~:text=After%20running%20PCA%2C%20SMOTE%20resampling,after%20the%20running%20of%20PCA.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def9a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_pca = SMOTE(k_neighbors=5)\n",
    "resampled_data_pca, resampled_labels_pca = oversample_pca.fit_resample(principalComponents, y_train) #X_resampled_pca_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6321d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_svd = SMOTE(k_neighbors=5)\n",
    "resampled_data_svd, resampled_labels_svd = oversample_svd.fit_resample(svd_reduced_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b140bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(k_neighbors=5)\n",
    "resampled_data, resampled_labels = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff55712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes and number of instances for each class:\n",
      "{0: 244, 1: 244, 2: 244, 3: 244, 4: 244}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(resampled_labels_pca, return_counts=True)\n",
    "print(\"Classes and number of instances for each class:\")\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_pca = TSNE(n_components=2,init='random').fit_transform(resampled_data_pca)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(8, figsize=(12, 12))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X_embedded_pca.T[0], X_embedded_pca.T[1], color=color[resampled_labels_pca])\n",
    "ax.set_title(\"TSNE visualisation after PCA+SMOTE\")\n",
    "plt.show()\n",
    "\n",
    "X_embedded_svd = TSNE(n_components=2,init='random').fit_transform(resampled_data_svd)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(9, figsize=(12, 12))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X_embedded_svd.T[0], X_embedded_svd.T[1], color=color[resampled_labels_svd])\n",
    "ax.set_title(\"TSNE visualisation after SVD+SMOTE\")\n",
    "plt.show()\n",
    "\n",
    "X_embedded_original = TSNE(n_components=2,init='random').fit_transform(resampled_data)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(10, figsize=(12, 12))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X_embedded_original.T[0], X_embedded_original.T[1], color=color[resampled_labels])\n",
    "ax.set_title(\"TSNE visualisation after SMOTE on original data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfefd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in test and train\n",
    "#X_train_resampled_pca, X_test_resampled_pca, y_train_resampled_pca, y_test_resampled_pca = train_test_split(resampled_data_pca, resampled_labels_pca, test_size=0.20)\n",
    "\n",
    "#X_train_resampled_svd, X_test_resampled_svd, y_train_resampled_svd, y_test_resampled_svd = train_test_split(resampled_data_svd, resampled_labels_svd, test_size=0.20)\n",
    "\n",
    "#X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(resampled_data, resampled_labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45f2df",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b363cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_KNN_pca = [('pca', PCA(n_components=0.95)), ('KNN', KNeighborsClassifier())]\n",
    "model_KNN_gs_pca = Pipeline(steps=steps_KNN_pca)\n",
    "parameters = {'KNN__n_neighbors':[1,3,5,7,9,11,13,15,17,19,21]}\n",
    "KNN_gs_pca = GridSearchCV(model_KNN_gs_pca, parameters,cv=10, verbose = 3)\n",
    "KNN_gs_pca.fit(X_train_resampled_pca,y_train_resampled_pca)\n",
    "\n",
    "print(KNN_gs_pca.best_params_)\n",
    "\n",
    "#gridsearch for decision tree classifier\n",
    "steps_PCA = [('pca', PCA(n_components=0.95)), ('tree', DecisionTreeClassifier())]\n",
    "model = Pipeline(steps=steps_PCA)\n",
    "parameters = {'tree__criterion':('entropy', 'gini'), 'tree__max_depth':[2,4,6,8,10,12,15,18,20], 'tree__max_features': ('sqrt', 'log2', None)}\n",
    "pca_pipeline = GridSearchCV(model, parameters, verbose = 3)\n",
    "pca_pipeline.fit(X_train_resampled_pca, y_train_resampled_pca)\n",
    "\n",
    "plt.figure(11)\n",
    "tree.plot_tree(pca_pipeline.best_estimator_['tree'],filled=True, fontsize=5)\n",
    "\n",
    "print(pca_pipeline.best_params_)\n",
    "print(pca_pipeline.score(X_test_pca, y_test_pca))\n",
    "\n",
    "#gridsearch for forest classifier\n",
    "steps_PCA = [('pca', PCA(n_components=0.95)), ('forest', RandomForestClassifier(n_jobs=-1))]\n",
    "model = Pipeline(steps=steps_PCA)\n",
    "parameters = {'forest__criterion':('entropy', 'gini'), 'forest__max_depth':[2,4,6,8,10,12,15,18,20], 'forest__max_features': ('auto', 'sqrt', 'log2', None)}\n",
    "pca_pipeline_forest = GridSearchCV(model, parameters, verbose = 3)\n",
    "pca_pipeline_forest.fit(X_train_resampled_pca, y_train_resampled_pca)\n",
    "\n",
    "print(pca_pipeline_forest.best_params_)\n",
    "print(pca_pipeline_forest.score(X_test_pca, y_test_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca812d",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03f73f4",
   "metadata": {},
   "source": [
    "After the data reduction and augmentation step we have 4 datasets:\n",
    "\n",
    "- Original data\n",
    "- Original data + SMOTE\n",
    "- Original data + PCA + SMOTE\n",
    "- Original data + SVD + SMOTE\n",
    "\n",
    " \n",
    "Next, we perform classification on these data on the following models \n",
    "- KNN: This is a baseline model\n",
    "- Decision tree \n",
    "- Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cac7dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy(original data):  0.9937888198757764\n",
      "[[56  0  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 1  0  0 28  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.98      1.00      0.99        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       1.00      1.00      1.00        33\n",
      "        LUAD       1.00      0.97      0.98        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       1.00      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "----------------\n",
      "----------------\n",
      "KNN Accuracy after PCA+SMOTE: 1.0\n",
      "[[56  0  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 0  0  0 29  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(PCA+SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       1.00      1.00      1.00        33\n",
      "        LUAD       1.00      1.00      1.00        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n",
      "----------------\n",
      "----------------\n",
      "KNN Accuracy after SVD+SMOTE: 1.0\n",
      "[[56  0  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 0  0  0 29  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(SVD+SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       1.00      1.00      1.00        33\n",
      "        LUAD       1.00      1.00      1.00        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n",
      "----------------\n",
      "----------------\n",
      "KNN Accuracy after ORIGINAL+SMOTE: 1.0\n",
      "[[56  0  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 0  0  0 29  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL+SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       1.00      1.00      1.00        33\n",
      "        LUAD       1.00      1.00      1.00        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n",
      "----------------\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "#knn results on original data\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy(original data): \", acc)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "print(\"----------------\")\n",
    "print(\"----------------\")\n",
    "\n",
    "#knn results on PCA+SMOTE\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(resampled_data_pca,resampled_labels_pca)\n",
    "X_test_projected_pca = pca.transform(X_test)\n",
    "y_pred = model.predict(X_test_projected_pca)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy after PCA+SMOTE:\", acc)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(PCA+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "print(\"----------------\")\n",
    "print(\"----------------\")\n",
    "\n",
    "#knn results on SVD+SMOTE\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(resampled_data_svd, resampled_labels_svd)\n",
    "X_test_projected_svd = svd.transform(X_test)\n",
    "y_pred = model.predict(X_test_projected_svd)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy after SVD+SMOTE:\", acc)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(SVD+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "print(\"----------------\")\n",
    "print(\"----------------\")\n",
    "\n",
    "#knn results on ORIGINAL+SMOTE\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(resampled_data, resampled_labels)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy after ORIGINAL+SMOTE:\", acc)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "print(\"----------------\")\n",
    "print(\"----------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e38a822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56  0  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 1  0 32  0  0]\n",
      " [ 1  0  1 27  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(SVD)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.97      1.00      0.98        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       0.97      0.97      0.97        33\n",
      "        LUAD       1.00      0.93      0.96        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.99      0.98      0.98       161\n",
      "weighted avg       0.98      0.98      0.98       161\n",
      "\n",
      "[[55  0  0  1  0]\n",
      " [ 0 17  0  1  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 1  0  1 27  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(PCA)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.98      0.98      0.98        56\n",
      "        COAD       1.00      0.94      0.97        18\n",
      "        KIRC       0.97      1.00      0.99        33\n",
      "        LUAD       0.93      0.93      0.93        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.98      0.97      0.97       161\n",
      "weighted avg       0.98      0.98      0.98       161\n",
      "\n",
      "[[56  0  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 0  0  0 29  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       1.00      1.00      1.00        33\n",
      "        LUAD       1.00      1.00      1.00        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svd on non-smote\n",
    "tree_svd = DecisionTreeClassifier(random_state=0)\n",
    "tree_svd.fit(svd_reduced_data, y_train)\n",
    "y_pred = tree_svd.predict(X_test_projected_svd)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(SVD)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "tree_pca = DecisionTreeClassifier(random_state=0)\n",
    "tree_pca.fit(principalComponents, y_train)\n",
    "y_pred = tree_pca.predict(X_test_projected_pca)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(PCA)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "\n",
    "tree_original = DecisionTreeClassifier(random_state=0)\n",
    "tree_original.fit(X_train, y_train)\n",
    "y_pred = tree_original.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98d37be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  0  0  1  1]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 3  0  1 25  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(SVD)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.95      0.96      0.96        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       0.97      1.00      0.99        33\n",
      "        LUAD       0.96      0.86      0.91        29\n",
      "        PRAD       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.96       161\n",
      "   macro avg       0.97      0.97      0.97       161\n",
      "weighted avg       0.96      0.96      0.96       161\n",
      "\n",
      "[[53  0  0  1  2]\n",
      " [ 0 17  0  1  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 0  0  1 28  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(PCA)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      0.95      0.97        56\n",
      "        COAD       1.00      0.94      0.97        18\n",
      "        KIRC       0.97      1.00      0.99        33\n",
      "        LUAD       0.93      0.97      0.95        29\n",
      "        PRAD       0.93      1.00      0.96        25\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.97      0.97      0.97       161\n",
      "weighted avg       0.97      0.97      0.97       161\n",
      "\n",
      "[[56  0  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 0  0  0 29  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       1.00      1.00      1.00        33\n",
      "        LUAD       1.00      1.00      1.00        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svd on smote\n",
    "tree_svd = DecisionTreeClassifier(random_state=0)\n",
    "tree_svd.fit(resampled_data_svd, resampled_labels_svd)\n",
    "y_pred = tree_svd.predict(X_test_projected_svd)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(SVD+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "tree_pca = DecisionTreeClassifier(random_state=0)\n",
    "tree_pca.fit(resampled_data_pca, resampled_labels_pca)\n",
    "y_pred = tree_pca.predict(X_test_projected_pca)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(PCA+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "\n",
    "tree_original = DecisionTreeClassifier(random_state=0)\n",
    "tree_original.fit(resampled_data, resampled_labels)\n",
    "y_pred = tree_original.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3fb2b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf706a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svd on non-smote\n",
    "forest_svd = RandomForestClassifier(random_state=0)\n",
    "forest_svd.fit(svd_reduced_data, y_train)\n",
    "y_pred = tree_svd.predict(X_test_projected_svd)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(SVD)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "forest_pca = RandomForestClassifier(random_state=0)\n",
    "forest_pca.fit(principalComponents, y_train)\n",
    "y_pred = tree_pca.predict(X_test_projected_pca)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(PCA)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "\n",
    "forest_original = RandomForestClassifier(random_state=0)\n",
    "forest_original.fit(X_train, y_train)\n",
    "y_pred = forest_original.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a60518b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  0  0  1  1]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 3  0  1 25  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(SVD)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.95      0.96      0.96        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       0.97      1.00      0.99        33\n",
      "        LUAD       0.96      0.86      0.91        29\n",
      "        PRAD       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.96       161\n",
      "   macro avg       0.97      0.97      0.97       161\n",
      "weighted avg       0.96      0.96      0.96       161\n",
      "\n",
      "[[53  0  0  1  2]\n",
      " [ 0 17  0  1  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 0  0  1 28  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(PCA)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      0.95      0.97        56\n",
      "        COAD       1.00      0.94      0.97        18\n",
      "        KIRC       0.97      1.00      0.99        33\n",
      "        LUAD       0.93      0.97      0.95        29\n",
      "        PRAD       0.93      1.00      0.96        25\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.97      0.97      0.97       161\n",
      "weighted avg       0.97      0.97      0.97       161\n",
      "\n",
      "[[56  0  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0  0 33  0  0]\n",
      " [ 0  0  1 28  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        56\n",
      "        COAD       1.00      1.00      1.00        18\n",
      "        KIRC       0.97      1.00      0.99        33\n",
      "        LUAD       1.00      0.97      0.98        29\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svd on smote\n",
    "forest_svd = RandomForestClassifier(random_state=0)\n",
    "forest_svd.fit(resampled_data_svd, resampled_labels_svd)\n",
    "y_pred = forest_svd.predict(X_test_projected_svd)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(SVD+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "forest_pca = RandomForestClassifier(random_state=0)\n",
    "forest_pca.fit(resampled_data_pca, resampled_labels_pca)\n",
    "y_pred = forest_pca.predict(X_test_projected_pca)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(PCA+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "\n",
    "forest_original = RandomForestClassifier(random_state=0)\n",
    "forest_original.fit(resampled_data, resampled_labels)\n",
    "y_pred = forest_original.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef857a",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be49547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_means clustering(original data) Normalised mutual info score:  0.9643177891634916\n",
      "K_means clustering(PCA) Normalised mutual info score:  0.9643177891634916\n",
      "K_means clustering(SVD) Normalised mutual info score:  0.9643177891634916\n"
     ]
    }
   ],
   "source": [
    "#kmeans results on original data\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(X_train)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test)\n",
    "print(\"K_means clustering(original data) Normalised mutual info score: \", normalized_mutual_info_score(y_test, y_pred))\n",
    "\n",
    "#kmeans results on PCA\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(principalComponents)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test_projected_pca)\n",
    "print(\"K_means clustering(PCA) Normalised mutual info score: \", normalized_mutual_info_score(y_test, y_pred))\n",
    "\n",
    "#kmeans results on SVD\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(svd_reduced_data)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test_projected_svd)\n",
    "print(\"K_means clustering(SVD) Normalised mutual info score: \", normalized_mutual_info_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a23ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_means clustering(SMOTE+ORIGINAL) Normalised mutual info score:  0.9643177891634916\n",
      "K_means clustering(PCA+SMOTE) Normalised mutual info score:  0.9809892086990412\n",
      "K_means clustering(SVD+SMOTE) Normalised mutual info score:  0.9643177891634916\n"
     ]
    }
   ],
   "source": [
    "#kmeans results on original data\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(resampled_data)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test)\n",
    "print(\"K_means clustering(SMOTE+ORIGINAL) Normalised mutual info score: \", normalized_mutual_info_score(y_test, y_pred))\n",
    "\n",
    "#kmeans results on PCA\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(resampled_data_pca)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test_projected_pca)\n",
    "print(\"K_means clustering(PCA+SMOTE) Normalised mutual info score: \", normalized_mutual_info_score(y_test, y_pred))\n",
    "\n",
    "#kmeans results on SVD\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(resampled_data_svd)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test_projected_svd)\n",
    "print(\"K_means clustering(SVD+SMOTE) Normalised mutual info score: \", normalized_mutual_info_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b74498",
   "metadata": {},
   "source": [
    "### Results\n",
    "- Classification : we see good result with PCA + SMOTE \n",
    "- Clustering: we see good result with PCA+SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb8677",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8251e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tree_ensemble = VotingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=1)), ('forest', RandomForestClassifier())], voting='hard')\n",
    "knn_tree_ensemble.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "y_pred = knn_tree_ensemble.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test_pca, y_pred))\n",
    "print(\"Accuracy\",)\n",
    "print(\"Classification report(PCA)\")\n",
    "print(classification_report(y_test_pca, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6389b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
