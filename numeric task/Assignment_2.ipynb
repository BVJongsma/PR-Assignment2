{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required libraries\n",
    "\"\"\"\n",
    "!pip install imblearn\n",
    "!pip install pyQt5\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb052813",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PyQt5\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "%matplotlib qt \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dataloader import *\n",
    "import preprocessing\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#Using GridSearch to find the optimal value of K number of nearest neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#metrics for analysing our model\n",
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# oversampling technique\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b531c",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1beac219",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = Dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84f809",
   "metadata": {},
   "source": [
    "#### Scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d2424",
   "metadata": {},
   "source": [
    "scale all variables to have a mean of 0 and standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c6a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing.scale(handler.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cee63",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470feddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes and number of instances for each class:\n",
      "{'BRCA': 300, 'COAD': 78, 'KIRC': 146, 'LUAD': 141, 'PRAD': 136}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(handler.labels, return_counts=True)\n",
    "print(\"Classes and number of instances for each class:\")\n",
    "print(dict(zip(unique, counts)))\n",
    "plt.bar(unique,counts)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Different types of tumour\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d7adca",
   "metadata": {},
   "source": [
    "We notice that there is class imbalance and we can use *SMOTE(Synthetic Minority Oversampling Technique)* for increasing instances of the minority class\n",
    "We also can make use of downsampling to make sure each class is represented equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a0340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 801\n",
      "Number of genes: 20531\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\",len(data))\n",
    "print(\"Number of genes:\",len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfad95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(handler.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e5c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2,init='random').fit_transform(handler.data)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(4, figsize=(12, 12))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X_embedded.T[0], X_embedded.T[1], color=color[labels])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a62d31",
   "metadata": {},
   "source": [
    "#### Split original dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5978ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split  in test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(handler.data, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387aae00",
   "metadata": {},
   "source": [
    "## Feature selection and Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bea191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 530)\n",
      "Number of genes after dimension reduction using PCA: 530\n",
      "Explained variance of new dataset using PCA: 0.9501213818001684\n",
      "\n",
      "(801, 531)\n",
      "Number of genes after dimension reduction using SVD: 531\n",
      "Explained variance of new dataset using SVD: 0.9492336720567962\n"
     ]
    }
   ],
   "source": [
    "#with pca extract eigen pairs that explains 95% of the variance in the data.\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "#SVD dimension reduction\n",
    "svd = TruncatedSVD(n_components=531, random_state=0)\n",
    "\n",
    "#simultanously calculate eigen pairs and transform our data into the new coordinate frame\n",
    "principalComponents = pca.fit_transform(data)\n",
    "svd_reduced_data = svd.fit_transform(data)\n",
    "\n",
    "#check the amount of dimensions left after pca\n",
    "print(principalComponents.shape)\n",
    "print(\"Number of genes after dimension reduction using PCA:\",principalComponents.shape[1])\n",
    "print(\"Explained variance of new dataset using PCA:\",pca.explained_variance_ratio_.sum())\n",
    "print(\"\")\n",
    "print(svd_reduced_data.shape)\n",
    "print(\"Number of genes after dimension reduction using SVD:\",svd_reduced_data.shape[1])\n",
    "print(\"Explained variance of new dataset using SVD:\",svd.explained_variance_ratio_.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc82457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "#plot 3 most important principle components (3D plot)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(2,figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_title(\"Visualise data after applying PCA\")\n",
    "ax.scatter(principalComponents.T[0], principalComponents.T[1], principalComponents.T[2], color=color[labels])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1af955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "#plot 3 most important principle components (3D plot)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(2,figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_title(\"Visualise data after applying SVD\")\n",
    "ax.scatter(svd_reduced_data.T[0], svd_reduced_data.T[1], svd_reduced_data.T[2], color=color[labels])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962ea802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split  in test and train\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(principalComponents, labels, test_size=0.20)\n",
    "\n",
    "#split  in test and train\n",
    "X_train_svd, X_test_svd, y_train_svd, y_test_svd = train_test_split(svd_reduced_data, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002215ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3, figsize=(12, 12))\n",
    "ax = sn.heatmap(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e8f2f",
   "metadata": {},
   "source": [
    "## Augmentation (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "- SMOTE is applied after PCA is done\n",
    "- refer (https://arxiv.org/ftp/arxiv/papers/1403/1403.1949.pdf#:~:text=After%20running%20PCA%2C%20SMOTE%20resampling,after%20the%20running%20of%20PCA.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def9a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_pca = SMOTE(k_neighbors=5)\n",
    "resampled_data_pca, resampled_labels_pca = oversample_pca.fit_resample(principalComponents, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6321d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_svd = SMOTE(k_neighbors=5)\n",
    "resampled_data_svd, resampled_labels_svd = oversample_svd.fit_resample(svd_reduced_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b140bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(k_neighbors=5)\n",
    "resampled_data, resampled_labels = oversample.fit_resample(handler.data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff55712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes and number of instances for each class:\n",
      "{'BRCA': 300, 'COAD': 300, 'KIRC': 300, 'LUAD': 300, 'PRAD': 300}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(resampled_labels_pca, return_counts=True)\n",
    "print(\"Classes and number of instances for each class:\")\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dac08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_pca = TSNE(n_components=2,init='random').fit_transform(resampled_data_pca)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(9, figsize=(12, 12))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X_embedded_pca.T[0], X_embedded_pca.T[1], color=color[resampled_labels_pca])\n",
    "plt.show()\n",
    "\n",
    "X_embedded_svd = TSNE(n_components=2,init='random').fit_transform(resampled_data_svd)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(10, figsize=(12, 12))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X_embedded_svd.T[0], X_embedded_svd.T[1], color=color[resampled_labels_svd])\n",
    "plt.show()\n",
    "\n",
    "X_embedded_original = TSNE(n_components=2,init='random').fit_transform(resampled_data)\n",
    "color = np.array(['r', 'g', 'b', 'c', 'm'])\n",
    "fig = plt.figure(11, figsize=(12, 12))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(X_embedded_original.T[0], X_embedded_original.T[1], color=color[resampled_labels])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecfefd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in test and train\n",
    "X_train_resampled_pca, X_test_resampled_pca, y_train_resampled_pca, y_test_resampled_pca = train_test_split(resampled_data_pca, resampled_labels_pca, test_size=0.20)\n",
    "\n",
    "X_train_resampled_svd, X_test_resampled_svd, y_train_resampled_svd, y_test_resampled_svd = train_test_split(resampled_data_svd, resampled_labels_svd, test_size=0.20)\n",
    "\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(resampled_data, resampled_labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca812d",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03f73f4",
   "metadata": {},
   "source": [
    "##### - first knn on all different datasets\n",
    "##### - second decision trees on all different datasets\n",
    "##### - third random forest on all different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cac7dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy(original data):  1.0\n",
      "[[59  0  0  0  0]\n",
      " [ 0 14  0  0  0]\n",
      " [ 0  0 31  0  0]\n",
      " [ 0  0  0 32  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        59\n",
      "        COAD       1.00      1.00      1.00        14\n",
      "        KIRC       1.00      1.00      1.00        31\n",
      "        LUAD       1.00      1.00      1.00        32\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n",
      "KNN Accuracy after PCA+SMOTE: 0.9875776397515528\n",
      "[[59  0  0  2  0]\n",
      " [ 0 16  0  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0  0 35  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(PCA+SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      0.97      0.98        61\n",
      "        COAD       1.00      1.00      1.00        16\n",
      "        KIRC       1.00      1.00      1.00        24\n",
      "        LUAD       0.95      1.00      0.97        35\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "KNN Accuracy after SVD+SMOTE: 0.9937888198757764\n",
      "[[54  0  0  0  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 35  0  0]\n",
      " [ 0  0  0 31  0]\n",
      " [ 0  0  0  0 27]]\n",
      "Classification report(SVD+SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      0.98      0.99        55\n",
      "        COAD       1.00      1.00      1.00        13\n",
      "        KIRC       1.00      1.00      1.00        35\n",
      "        LUAD       1.00      1.00      1.00        31\n",
      "        PRAD       0.96      1.00      0.98        27\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      1.00      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "KNN Accuracy after ORIGINAL+SMOTE: 1.0\n",
      "[[59  0  0  0  0]\n",
      " [ 0 14  0  0  0]\n",
      " [ 0  0 31  0  0]\n",
      " [ 0  0  0 32  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL+SMOTE)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        59\n",
      "        COAD       1.00      1.00      1.00        14\n",
      "        KIRC       1.00      1.00      1.00        31\n",
      "        LUAD       1.00      1.00      1.00        32\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#knn results on original data\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy(original data): \", acc)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "#knn results on PCA+SMOTE\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train_resampled_pca,y_train_resampled_pca)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "acc = accuracy_score(y_test_pca, y_pred)\n",
    "print(\"KNN Accuracy after PCA+SMOTE:\", acc)\n",
    "print(confusion_matrix(y_test_pca, y_pred))\n",
    "print(\"Classification report(PCA+SMOTE)\")\n",
    "print(classification_report(y_test_pca, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "#knn results on SVD+SMOTE\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train_resampled_svd,y_train_resampled_svd)\n",
    "y_pred = model.predict(X_test_svd)\n",
    "acc = accuracy_score(y_test_svd, y_pred)\n",
    "print(\"KNN Accuracy after SVD+SMOTE:\", acc)\n",
    "print(confusion_matrix(y_test_svd, y_pred))\n",
    "print(\"Classification report(SVD+SMOTE)\")\n",
    "print(classification_report(y_test_svd, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "#knn results on ORIGINAL+SMOTE\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train_resampled,y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy after ORIGINAL+SMOTE:\", acc)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL+SMOTE)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e38a822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.972 (0.009)\n",
      "[[52  0  1  1  1]\n",
      " [ 0 12  0  1  0]\n",
      " [ 4  0 31  0  0]\n",
      " [ 3  2  0 26  0]\n",
      " [ 0  0  1  0 26]]\n",
      "Classification report(SVD)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.88      0.95      0.91        55\n",
      "        COAD       0.86      0.92      0.89        13\n",
      "        KIRC       0.94      0.89      0.91        35\n",
      "        LUAD       0.93      0.84      0.88        31\n",
      "        PRAD       0.96      0.96      0.96        27\n",
      "\n",
      "    accuracy                           0.91       161\n",
      "   macro avg       0.91      0.91      0.91       161\n",
      "weighted avg       0.91      0.91      0.91       161\n",
      "\n",
      "Accuracy: 0.972 (0.008)\n",
      "[[57  0  1  1  2]\n",
      " [ 0 16  0  0  0]\n",
      " [ 1  1 22  0  0]\n",
      " [ 1  1  1 32  0]\n",
      " [ 0  1  0  0 24]]\n",
      "Classification report(PCA)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.97      0.93      0.95        61\n",
      "        COAD       0.84      1.00      0.91        16\n",
      "        KIRC       0.92      0.92      0.92        24\n",
      "        LUAD       0.97      0.91      0.94        35\n",
      "        PRAD       0.92      0.96      0.94        25\n",
      "\n",
      "    accuracy                           0.94       161\n",
      "   macro avg       0.92      0.95      0.93       161\n",
      "weighted avg       0.94      0.94      0.94       161\n",
      "\n",
      "Accuracy: 0.967 (0.016)\n",
      "[[59  0  0  0  0]\n",
      " [ 0 13  0  1  0]\n",
      " [ 0  0 31  0  0]\n",
      " [ 2  1  0 29  0]\n",
      " [ 1  0  0  0 24]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.95      1.00      0.98        59\n",
      "        COAD       0.93      0.93      0.93        14\n",
      "        KIRC       1.00      1.00      1.00        31\n",
      "        LUAD       0.97      0.91      0.94        32\n",
      "        PRAD       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.97       161\n",
      "   macro avg       0.97      0.96      0.96       161\n",
      "weighted avg       0.97      0.97      0.97       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_SVD = [('svd', TruncatedSVD(n_components=530)), ('tree', DecisionTreeClassifier())]\n",
    "model = Pipeline(steps=steps_SVD)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train , y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "model.fit(X_train_svd, y_train_svd)\n",
    "y_pred = model.predict(X_test_svd)\n",
    "print(confusion_matrix(y_test_svd, y_pred))\n",
    "print(\"Classification report(SVD)\")\n",
    "print(classification_report(y_test_svd, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "steps_PCA = [('pca', PCA(n_components=0.95)), ('tree', DecisionTreeClassifier())]\n",
    "model = Pipeline(steps=steps_PCA)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train , y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "model.fit(X_train_pca, y_train_pca)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test_pca, y_pred))\n",
    "print(\"Classification report(PCA)\")\n",
    "print(classification_report(y_test_pca, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "steps_ORIGINAL = [('tree', DecisionTreeClassifier())]\n",
    "model = Pipeline(steps=steps_ORIGINAL)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train , y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03e13f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953 (0.024)\n",
      "[[54  0  0  0  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 35  0  0]\n",
      " [ 0  0  1 30  0]\n",
      " [ 0  0  0  1 26]]\n",
      "Classification report(SVD)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      0.98      0.99        55\n",
      "        COAD       1.00      1.00      1.00        13\n",
      "        KIRC       0.97      1.00      0.99        35\n",
      "        LUAD       0.97      0.97      0.97        31\n",
      "        PRAD       0.96      0.96      0.96        27\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.98      0.98      0.98       161\n",
      "weighted avg       0.98      0.98      0.98       161\n",
      "\n",
      "Accuracy: 0.968 (0.013)\n",
      "[[60  1  0  0  0]\n",
      " [ 0 16  0  0  0]\n",
      " [ 1  0 23  0  0]\n",
      " [ 0  0  0 35  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(PCA)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.98      0.98      0.98        61\n",
      "        COAD       0.94      1.00      0.97        16\n",
      "        KIRC       1.00      0.96      0.98        24\n",
      "        LUAD       1.00      1.00      1.00        35\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.98      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "Accuracy: 0.987 (0.002)\n",
      "[[59  0  0  0  0]\n",
      " [ 0 14  0  0  0]\n",
      " [ 0  0 31  0  0]\n",
      " [ 1  0  0 31  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.98      1.00      0.99        59\n",
      "        COAD       1.00      1.00      1.00        14\n",
      "        KIRC       1.00      1.00      1.00        31\n",
      "        LUAD       1.00      0.97      0.98        32\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       1.00      0.99      1.00       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVD + SMOTE\n",
    "steps_SVD = [('svd', TruncatedSVD(n_components=530)), ('tree', DecisionTreeClassifier())]\n",
    "model = Pipeline(steps=steps_SVD)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train_resampled_svd , y_train_resampled_svd, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "model.fit(X_train_resampled_svd, y_train_resampled_svd)\n",
    "y_pred = model.predict(X_test_svd)\n",
    "print(confusion_matrix(y_test_svd, y_pred))\n",
    "print(\"Classification report(SVD)\")\n",
    "print(classification_report(y_test_svd, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "#PCA + SMOTE\n",
    "steps_PCA = [('pca', PCA(n_components=0.95)), ('tree', DecisionTreeClassifier())]\n",
    "model = Pipeline(steps=steps_PCA)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train_resampled_pca , y_train_resampled_pca, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "model.fit(X_train_resampled_pca, y_train_resampled_pca)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test_pca, y_pred))\n",
    "print(\"Classification report(PCA)\")\n",
    "print(classification_report(y_test_pca, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "#ORIGINAL + SMOTE\n",
    "steps_ORIGINAL = [('tree', DecisionTreeClassifier())]\n",
    "model = Pipeline(steps=steps_ORIGINAL)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train_resampled , y_train_resampled, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3fb2b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbf706a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975 (0.014)\n",
      "[[54  0  0  0  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 35  0  0]\n",
      " [ 5  0  1 25  0]\n",
      " [ 0  0  0  0 27]]\n",
      "Classification report(SVD)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.92      0.98      0.95        55\n",
      "        COAD       1.00      1.00      1.00        13\n",
      "        KIRC       0.97      1.00      0.99        35\n",
      "        LUAD       1.00      0.81      0.89        31\n",
      "        PRAD       0.96      1.00      0.98        27\n",
      "\n",
      "    accuracy                           0.96       161\n",
      "   macro avg       0.97      0.96      0.96       161\n",
      "weighted avg       0.96      0.96      0.96       161\n",
      "\n",
      "Accuracy: 0.988 (0.009)\n",
      "[[61  0  0  0  0]\n",
      " [ 0 16  0  0  0]\n",
      " [ 2  0 22  0  0]\n",
      " [ 3  0  0 32  0]\n",
      " [ 1  0  0  0 24]]\n",
      "Classification report(PCA)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.91      1.00      0.95        61\n",
      "        COAD       1.00      1.00      1.00        16\n",
      "        KIRC       1.00      0.92      0.96        24\n",
      "        LUAD       1.00      0.91      0.96        35\n",
      "        PRAD       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.96       161\n",
      "   macro avg       0.98      0.96      0.97       161\n",
      "weighted avg       0.97      0.96      0.96       161\n",
      "\n",
      "Accuracy: 0.995 (0.006)\n",
      "[[59  0  0  0  0]\n",
      " [ 0 14  0  0  0]\n",
      " [ 0  0 31  0  0]\n",
      " [ 0  0  0 32  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        59\n",
      "        COAD       1.00      1.00      1.00        14\n",
      "        KIRC       1.00      1.00      1.00        31\n",
      "        LUAD       1.00      1.00      1.00        32\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_SVD = [('svd', TruncatedSVD(n_components=530)), ('tree', RandomForestClassifier())]\n",
    "model = Pipeline(steps=steps_SVD)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train , y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "model.fit(X_train_svd, y_train_svd)\n",
    "y_pred = model.predict(X_test_svd)\n",
    "print(confusion_matrix(y_test_svd, y_pred))\n",
    "print(\"Classification report(SVD)\")\n",
    "print(classification_report(y_test_svd, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "steps_PCA = [('pca', PCA(n_components=0.95)), ('tree', RandomForestClassifier())]\n",
    "model = Pipeline(steps=steps_PCA)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train , y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "model.fit(X_train_pca, y_train_pca)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test_pca, y_pred))\n",
    "print(\"Classification report(PCA)\")\n",
    "print(classification_report(y_test_pca, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "steps_ORIGINAL = [('tree', RandomForestClassifier())]\n",
    "model = Pipeline(steps=steps_ORIGINAL)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train , y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a60518b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.983 (0.005)\n",
      "[[54  0  0  0  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 35  0  0]\n",
      " [ 1  0  0 30  0]\n",
      " [ 0  0  0  0 27]]\n",
      "Classification report(SVD)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.98      0.98      0.98        55\n",
      "        COAD       1.00      1.00      1.00        13\n",
      "        KIRC       1.00      1.00      1.00        35\n",
      "        LUAD       1.00      0.97      0.98        31\n",
      "        PRAD       0.96      1.00      0.98        27\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "Accuracy: 0.993 (0.005)\n",
      "[[60  0  0  1  0]\n",
      " [ 0 16  0  0  0]\n",
      " [ 1  0 23  0  0]\n",
      " [ 0  0  0 35  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(PCA)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.98      0.98      0.98        61\n",
      "        COAD       1.00      1.00      1.00        16\n",
      "        KIRC       1.00      0.96      0.98        24\n",
      "        LUAD       0.97      1.00      0.99        35\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n",
      "Accuracy: 0.999 (0.002)\n",
      "[[59  0  0  0  0]\n",
      " [ 0 14  0  0  0]\n",
      " [ 0  0 31  0  0]\n",
      " [ 0  0  0 32  0]\n",
      " [ 0  0  0  0 25]]\n",
      "Classification report(ORIGINAL)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       1.00      1.00      1.00        59\n",
      "        COAD       1.00      1.00      1.00        14\n",
      "        KIRC       1.00      1.00      1.00        31\n",
      "        LUAD       1.00      1.00      1.00        32\n",
      "        PRAD       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVD + SMOTE\n",
    "steps_SVD = [('svd', TruncatedSVD(n_components=530)), ('tree', RandomForestClassifier())]\n",
    "model = Pipeline(steps=steps_SVD)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train_resampled_svd , y_train_resampled_svd, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "model.fit(X_train_resampled_svd, y_train_resampled_svd)\n",
    "y_pred = model.predict(X_test_svd)\n",
    "print(confusion_matrix(y_test_svd, y_pred))\n",
    "print(\"Classification report(SVD)\")\n",
    "print(classification_report(y_test_svd, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "#PCA + SMOTE\n",
    "steps_PCA = [('pca', PCA(n_components=0.95)), ('tree', RandomForestClassifier())]\n",
    "model = Pipeline(steps=steps_PCA)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train_resampled_pca , y_train_resampled_pca, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "model.fit(X_train_resampled_pca, y_train_resampled_pca)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test_pca, y_pred))\n",
    "print(\"Classification report(PCA)\")\n",
    "print(classification_report(y_test_pca, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))\n",
    "\n",
    "#ORIGINAL + SMOTE\n",
    "steps_ORIGINAL = [('tree', RandomForestClassifier())]\n",
    "model = Pipeline(steps=steps_ORIGINAL)\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "n_scores = cross_val_score(model, X_train_resampled , y_train_resampled, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification report(ORIGINAL)\")\n",
    "print(classification_report(y_test, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef857a",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be49547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_means clustering(original data) Normalised mutual info score:  1.0000000000000002\n",
      "K_means clustering(PCA+SMOTE) Normalised mutual info score:  0.8973934492765573\n",
      "K_means clustering(SVD+SMOTE) Normalised mutual info score:  0.9204556672160968\n"
     ]
    }
   ],
   "source": [
    "#kmeans results on original data\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(X_train)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test)\n",
    "print(\"K_means clustering(original data) Normalised mutual info score: \", normalized_mutual_info_score(y_test, y_pred))\n",
    "\n",
    "#kmeans results on PCA\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(X_train_pca)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test_pca)\n",
    "print(\"K_means clustering(PCA+SMOTE) Normalised mutual info score: \", normalized_mutual_info_score(y_test_pca, y_pred))\n",
    "\n",
    "#kmeans results on SVD\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(X_train_svd)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test_svd)\n",
    "print(\"K_means clustering(SVD+SMOTE) Normalised mutual info score: \", normalized_mutual_info_score(y_test_svd, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a23ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_means clustering(original data) Normalised mutual info score:  1.0000000000000002\n",
      "K_means clustering(PCA+SMOTE) Normalised mutual info score:  0.9484269175156541\n",
      "K_means clustering(SVD+SMOTE) Normalised mutual info score:  0.9617647314480207\n"
     ]
    }
   ],
   "source": [
    "#kmeans results on original data + SMOTE\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(X_train_resampled)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test)\n",
    "print(\"K_means clustering(original data) Normalised mutual info score: \", normalized_mutual_info_score(y_test, y_pred))\n",
    "\n",
    "#kmeans results on PCA+SMOTE\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(X_train_resampled_pca)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test_pca)\n",
    "print(\"K_means clustering(PCA+SMOTE) Normalised mutual info score: \", normalized_mutual_info_score(y_test_pca, y_pred))\n",
    "\n",
    "#kmeans results on SVD+SMOTE\n",
    "kmeans = KMeans(n_clusters=len(np.unique(handler.labels)), random_state=0).fit(X_train_resampled_svd)\n",
    "labels_kmeans = le.fit_transform(kmeans.labels_)\n",
    "y_pred = kmeans.predict(X_test_svd)\n",
    "print(\"K_means clustering(SVD+SMOTE) Normalised mutual info score: \", normalized_mutual_info_score(y_test_svd, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b74498",
   "metadata": {},
   "source": [
    "#### we see good result with PCA + SMOTE for classification and for clustering SVD+SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1410a",
   "metadata": {},
   "source": [
    "## Grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519bfa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_KNN_pca = [('pca', PCA(n_components=0.95)), ('KNN', KNeighborsClassifier())]\n",
    "model_KNN_gs_pca = Pipeline(steps=steps_KNN_pca)\n",
    "parameters = {'KNN__n_neighbors':[1,3,5,7,9,11,13,15,17,19,21]}\n",
    "KNN_gs_pca = GridSearchCV(model_KNN_gs_pca, parameters,cv=10, verbose = 3)\n",
    "KNN_gs_pca.fit(X_train_resampled_pca,y_train_resampled_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KNN_gs_pca.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbfceaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END ...........tree__criterion=entropy;, score=0.971 total time=   0.2s\n",
      "[CV 2/5] END ...........tree__criterion=entropy;, score=0.946 total time=   0.2s\n",
      "[CV 3/5] END ...........tree__criterion=entropy;, score=0.963 total time=   0.2s\n",
      "[CV 4/5] END ...........tree__criterion=entropy;, score=0.996 total time=   0.2s\n",
      "[CV 5/5] END ...........tree__criterion=entropy;, score=0.958 total time=   0.2s\n",
      "[CV 1/5] END ..............tree__criterion=gini;, score=0.979 total time=   0.1s\n",
      "[CV 2/5] END ..............tree__criterion=gini;, score=0.950 total time=   0.1s\n",
      "[CV 3/5] END ..............tree__criterion=gini;, score=0.971 total time=   0.1s\n",
      "[CV 4/5] END ..............tree__criterion=gini;, score=0.975 total time=   0.1s\n",
      "[CV 5/5] END ..............tree__criterion=gini;, score=0.971 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('pca', PCA(n_components=0.95)),\n",
       "                                       ('tree', DecisionTreeClassifier())]),\n",
       "             param_grid={'tree__criterion': ('entropy', 'gini')}, verbose=3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gridsearch for decision tree classifier\n",
    "steps_PCA = [('pca', PCA(n_components=0.95)), ('tree', DecisionTreeClassifier())]\n",
    "model = Pipeline(steps=steps_PCA)\n",
    "parameters = {'tree__criterion':('entropy', 'gini'), 'tree__max_depth':[2,4,6,8,10,12,15,18,20], 'max_features': ('auto', 'sqrt', 'log2', 'None')}\n",
    "pca_pipeline = GridSearchCV(model, parameters, verbose = 3)\n",
    "pca_pipeline.fit(X_train_resampled_pca, y_train_resampled_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8213c61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(310.5166666666667, 354.2, 'X[1] <= 43.823\\ngini = 0.8\\nsamples = 1200\\nvalue = [236, 238, 243, 243, 240]'),\n",
       " Text(246.9666666666667, 323.4, 'X[0] <= -44.805\\ngini = 0.751\\nsamples = 962\\nvalue = [235, 238, 243, 243, 3]'),\n",
       " Text(169.4666666666667, 292.59999999999997, 'X[2] <= -31.064\\ngini = 0.043\\nsamples = 229\\nvalue = [5, 0, 224, 0, 0]'),\n",
       " Text(152.93333333333334, 261.79999999999995, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0, 0, 0]'),\n",
       " Text(186.00000000000003, 261.79999999999995, 'gini = 0.0\\nsamples = 224\\nvalue = [0, 0, 224, 0, 0]'),\n",
       " Text(324.4666666666667, 292.59999999999997, 'X[0] <= 41.655\\ngini = 0.686\\nsamples = 733\\nvalue = [230, 238, 19, 243, 3]'),\n",
       " Text(219.0666666666667, 261.79999999999995, 'X[4] <= -0.378\\ngini = 0.577\\nsamples = 501\\nvalue = [222, 20, 19, 237, 3]'),\n",
       " Text(124.00000000000001, 230.99999999999997, 'X[6] <= 37.392\\ngini = 0.224\\nsamples = 243\\nvalue = [6, 20, 1, 213, 3]'),\n",
       " Text(82.66666666666667, 200.2, 'X[3] <= -0.938\\ngini = 0.095\\nsamples = 224\\nvalue = [5, 3, 1, 213, 2]'),\n",
       " Text(49.60000000000001, 169.39999999999998, 'X[227] <= -0.48\\ngini = 0.611\\nsamples = 6\\nvalue = [3, 2, 0, 0, 1]'),\n",
       " Text(33.06666666666667, 138.6, 'X[122] <= 0.989\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 0, 0, 1]'),\n",
       " Text(16.533333333333335, 107.80000000000001, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0, 0, 0]'),\n",
       " Text(49.60000000000001, 107.80000000000001, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1]'),\n",
       " Text(66.13333333333334, 138.6, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0, 0, 0]'),\n",
       " Text(115.73333333333335, 169.39999999999998, 'X[31] <= 22.672\\ngini = 0.045\\nsamples = 218\\nvalue = [2, 1, 1, 213, 1]'),\n",
       " Text(99.20000000000002, 138.6, 'X[274] <= -8.107\\ngini = 0.036\\nsamples = 217\\nvalue = [2, 1, 0, 213, 1]'),\n",
       " Text(82.66666666666667, 107.80000000000001, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1]'),\n",
       " Text(115.73333333333335, 107.80000000000001, 'X[10] <= -29.93\\ngini = 0.027\\nsamples = 216\\nvalue = [2, 1, 0, 213, 0]'),\n",
       " Text(99.20000000000002, 77.0, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0, 0, 0]'),\n",
       " Text(132.26666666666668, 77.0, 'X[229] <= -9.993\\ngini = 0.018\\nsamples = 215\\nvalue = [2, 0, 0, 213, 0]'),\n",
       " Text(115.73333333333335, 46.19999999999999, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0]'),\n",
       " Text(148.8, 46.19999999999999, 'X[5] <= -44.657\\ngini = 0.009\\nsamples = 214\\nvalue = [1, 0, 0, 213, 0]'),\n",
       " Text(132.26666666666668, 15.399999999999977, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0]'),\n",
       " Text(165.33333333333334, 15.399999999999977, 'gini = 0.0\\nsamples = 213\\nvalue = [0, 0, 0, 213, 0]'),\n",
       " Text(132.26666666666668, 138.6, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1, 0, 0]'),\n",
       " Text(165.33333333333334, 200.2, 'X[294] <= 1.038\\ngini = 0.194\\nsamples = 19\\nvalue = [1, 17, 0, 0, 1]'),\n",
       " Text(148.8, 169.39999999999998, 'gini = 0.0\\nsamples = 17\\nvalue = [0, 17, 0, 0, 0]'),\n",
       " Text(181.86666666666667, 169.39999999999998, 'X[220] <= -1.461\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 0, 0, 0, 1]'),\n",
       " Text(165.33333333333334, 138.6, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0]'),\n",
       " Text(198.40000000000003, 138.6, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 0, 1]'),\n",
       " Text(314.1333333333334, 230.99999999999997, 'X[5] <= 35.062\\ngini = 0.286\\nsamples = 258\\nvalue = [216, 0, 18, 24, 0]'),\n",
       " Text(281.0666666666667, 200.2, 'X[10] <= 25.526\\ngini = 0.123\\nsamples = 231\\nvalue = [216, 0, 12, 3, 0]'),\n",
       " Text(264.53333333333336, 169.39999999999998, 'X[12] <= 24.771\\ngini = 0.053\\nsamples = 222\\nvalue = [216, 0, 3, 3, 0]'),\n",
       " Text(231.4666666666667, 138.6, 'X[147] <= 15.355\\ngini = 0.009\\nsamples = 216\\nvalue = [215, 0, 0, 1, 0]'),\n",
       " Text(214.93333333333337, 107.80000000000001, 'gini = 0.0\\nsamples = 215\\nvalue = [215, 0, 0, 0, 0]'),\n",
       " Text(248.00000000000003, 107.80000000000001, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 0, 1, 0]'),\n",
       " Text(297.6, 138.6, 'X[229] <= 6.026\\ngini = 0.611\\nsamples = 6\\nvalue = [1, 0, 3, 2, 0]'),\n",
       " Text(281.0666666666667, 107.80000000000001, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3, 0, 0]'),\n",
       " Text(314.1333333333334, 107.80000000000001, 'X[198] <= -3.17\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 0, 0, 2, 0]'),\n",
       " Text(297.6, 77.0, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0]'),\n",
       " Text(330.6666666666667, 77.0, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 0, 2, 0]'),\n",
       " Text(297.6, 169.39999999999998, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 0, 9, 0, 0]'),\n",
       " Text(347.20000000000005, 200.2, 'X[0] <= -12.492\\ngini = 0.346\\nsamples = 27\\nvalue = [0, 0, 6, 21, 0]'),\n",
       " Text(330.6666666666667, 169.39999999999998, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 6, 0, 0]'),\n",
       " Text(363.73333333333335, 169.39999999999998, 'gini = 0.0\\nsamples = 21\\nvalue = [0, 0, 0, 21, 0]'),\n",
       " Text(429.86666666666673, 261.79999999999995, 'X[3] <= 22.953\\ngini = 0.115\\nsamples = 232\\nvalue = [8, 218, 0, 6, 0]'),\n",
       " Text(396.80000000000007, 230.99999999999997, 'X[155] <= -7.886\\ngini = 0.027\\nsamples = 221\\nvalue = [3, 218, 0, 0, 0]'),\n",
       " Text(380.2666666666667, 200.2, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0, 0, 0]'),\n",
       " Text(413.33333333333337, 200.2, 'gini = 0.0\\nsamples = 218\\nvalue = [0, 218, 0, 0, 0]'),\n",
       " Text(462.9333333333334, 230.99999999999997, 'X[122] <= -2.533\\ngini = 0.496\\nsamples = 11\\nvalue = [5, 0, 0, 6, 0]'),\n",
       " Text(446.40000000000003, 200.2, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0, 0, 0, 0]'),\n",
       " Text(479.4666666666667, 200.2, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 0, 0, 6, 0]'),\n",
       " Text(374.0666666666667, 323.4, 'X[116] <= -14.466\\ngini = 0.008\\nsamples = 238\\nvalue = [1, 0, 0, 0, 237]'),\n",
       " Text(357.53333333333336, 292.59999999999997, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0, 0, 0, 0]'),\n",
       " Text(390.6, 292.59999999999997, 'gini = 0.0\\nsamples = 237\\nvalue = [0, 0, 0, 0, 237]')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.plot_tree(pca_pipeline.best_estimator_['tree'],filled=True, fontsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c844e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tree__criterion': 'gini'}\n",
      "0.9875776397515528\n"
     ]
    }
   ],
   "source": [
    "print(pca_pipeline.best_params_)\n",
    "print(pca_pipeline.score(X_test_pca, y_test_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b47aa4",
   "metadata": {},
   "source": [
    "## TODO: plot mean accuracies of all models from gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pca_pipeline.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch for forest classifier\n",
    "steps_PCA = [('pca', PCA(n_components=0.95)), ('forest', RandomForestClassifier(n_jobs=-1))]\n",
    "model = Pipeline(steps=steps_PCA)\n",
    "parameters = {'forest__criterion':('entropy', 'gini'), 'forest__max_depth':[2,4,6,8,10,12,15,18,20], 'forest__max_features': ('auto', 'sqrt', 'log2', 'None')}\n",
    "pca_pipeline_forest = GridSearchCV(model, parameters, verbose = 3)\n",
    "pca_pipeline_forest.fit(X_train_resampled_pca, y_train_resampled_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe07eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_pipeline_forest.best_params_)\n",
    "print(pca_pipeline_forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb8677",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8251e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tree_ensemble = VotingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=1)), ('tree', DecisionTreeClassifier())], voting='hard')\n",
    "knn_tree_ensemble.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "y_pred = knn_tree_ensemble.predict(X_test_pca)\n",
    "print(confusion_matrix(y_test_pca, y_pred))\n",
    "print(\"Classification report(PCA)\")\n",
    "print(classification_report(y_test_pca, y_pred, target_names=['BRCA','COAD','KIRC','LUAD','PRAD']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
